{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW4 - Machine Translation(LSTM) ver.2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNYOlGU2413sWpEyztzF899"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmMW-ovX1AUR","executionInfo":{"status":"ok","timestamp":1642064738056,"user_tz":-480,"elapsed":1111,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"983c2afa-1281-4de8-955d-9a0e9c21b090"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-13 09:05:36--  http://www.manythings.org/anki/fra-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3030::6815:5c2c, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6532197 (6.2M) [application/zip]\n","Saving to: ‘fra-eng.zip’\n","\n","\rfra-eng.zip           0%[                    ]       0  --.-KB/s               \rfra-eng.zip         100%[===================>]   6.23M  --.-KB/s    in 0.09s   \n","\n","2022-01-13 09:05:36 (66.8 MB/s) - ‘fra-eng.zip’ saved [6532197/6532197]\n","\n","Archive:  fra-eng.zip\n","  inflating: _about.txt              \n","  inflating: fra.txt                 \n"]}],"source":["!wget -c http://www.manythings.org/anki/fra-eng.zip && unzip -o fra-eng.zip"]},{"cell_type":"code","source":["import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from keras.layers import Dense, Embedding, Input, LSTM\n","import numpy as np"],"metadata":{"id":"7K8TOkiD1OOS","executionInfo":{"status":"ok","timestamp":1642064740276,"user_tz":-480,"elapsed":2225,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('fra.txt', sep='\\t', header=None)\n","df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n","df.columns = ['English', 'French']\n","\n","df = df[0:60000]\n","df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"BwORjg1s1PUK","executionInfo":{"status":"ok","timestamp":1642064741385,"user_tz":-480,"elapsed":1112,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"2cb59c61-5dfe-40a1-ba48-0ddc3c9f01e9"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-23437349-fc59-4f28-be87-1d5b1e4643e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>French</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17228</th>\n","      <td>Close the window.</td>\n","      <td>Fermez la fenêtre !</td>\n","    </tr>\n","    <tr>\n","      <th>52355</th>\n","      <td>We're behind schedule.</td>\n","      <td>Nous sommes en retard sur l'emploi du temps.</td>\n","    </tr>\n","    <tr>\n","      <th>51782</th>\n","      <td>Tom didn't feel tired.</td>\n","      <td>Tom ne s'est pas senti fatigué.</td>\n","    </tr>\n","    <tr>\n","      <th>54203</th>\n","      <td>Don't make me kill you.</td>\n","      <td>Ne m'obligez pas à vous tuer !</td>\n","    </tr>\n","    <tr>\n","      <th>57208</th>\n","      <td>Let's go and say hello.</td>\n","      <td>Allons-y dire bonjour.</td>\n","    </tr>\n","    <tr>\n","      <th>21838</th>\n","      <td>You'll need this.</td>\n","      <td>Tu auras besoin de ça.</td>\n","    </tr>\n","    <tr>\n","      <th>11457</th>\n","      <td>She loves cats.</td>\n","      <td>Elle adore les chats.</td>\n","    </tr>\n","    <tr>\n","      <th>23493</th>\n","      <td>I have a daughter.</td>\n","      <td>J'ai une fille.</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>Help me.</td>\n","      <td>Aide-moi.</td>\n","    </tr>\n","    <tr>\n","      <th>20217</th>\n","      <td>The room is dark.</td>\n","      <td>La pièce est sombre.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23437349-fc59-4f28-be87-1d5b1e4643e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-23437349-fc59-4f28-be87-1d5b1e4643e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-23437349-fc59-4f28-be87-1d5b1e4643e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                       English                                        French\n","17228        Close the window.                           Fermez la fenêtre !\n","52355   We're behind schedule.  Nous sommes en retard sur l'emploi du temps.\n","51782   Tom didn't feel tired.               Tom ne s'est pas senti fatigué.\n","54203  Don't make me kill you.                Ne m'obligez pas à vous tuer !\n","57208  Let's go and say hello.                        Allons-y dire bonjour.\n","21838        You'll need this.                        Tu auras besoin de ça.\n","11457          She loves cats.                         Elle adore les chats.\n","23493       I have a daughter.                               J'ai une fille.\n","299                   Help me.                                     Aide-moi.\n","20217        The room is dark.                          La pièce est sombre."]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# <sos> : start of sentence (use '\\t')\n","# <eos> : end of sentence   (use '\\n')\n","\n","df.French = df.French.apply(lambda x: '\\t ' + x + ' \\n')\n","df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"ArwLuJpg1TzD","executionInfo":{"status":"ok","timestamp":1642064741386,"user_tz":-480,"elapsed":23,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"3ba3d74e-9dfc-42d8-fa10-75d650505d4f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7bd52e8b-3de1-412d-8731-f2fbc0b47eb7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>French</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>29780</th>\n","      <td>I was not drinking.</td>\n","      <td>\\t Je n'étais pas en train de boire. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>24384</th>\n","      <td>I'm proud of that.</td>\n","      <td>\\t Je suis fière de cela. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>54579</th>\n","      <td>He is a very smart boy.</td>\n","      <td>\\t C'est un garçon très intelligent. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>29435</th>\n","      <td>I love my children.</td>\n","      <td>\\t J'aime mes enfants. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>55838</th>\n","      <td>I read a lot of novels.</td>\n","      <td>\\t Je lis de nombreux romans. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>31000</th>\n","      <td>She put on her hat.</td>\n","      <td>\\t Elle a mis son chapeau. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>39490</th>\n","      <td>You should dump Tom.</td>\n","      <td>\\t Tu devrais rompre avec Tom. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>41649</th>\n","      <td>I have a good salary.</td>\n","      <td>\\t J'ai un bon salaire. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>34992</th>\n","      <td>I can't swim at all.</td>\n","      <td>\\t Je ne sais pas du tout nager. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>786</th>\n","      <td>Tom left.</td>\n","      <td>\\t Tom est parti. \\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bd52e8b-3de1-412d-8731-f2fbc0b47eb7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7bd52e8b-3de1-412d-8731-f2fbc0b47eb7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7bd52e8b-3de1-412d-8731-f2fbc0b47eb7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                       English                                   French\n","29780      I was not drinking.  \\t Je n'étais pas en train de boire. \\n\n","24384       I'm proud of that.             \\t Je suis fière de cela. \\n\n","54579  He is a very smart boy.  \\t C'est un garçon très intelligent. \\n\n","29435      I love my children.                \\t J'aime mes enfants. \\n\n","55838  I read a lot of novels.         \\t Je lis de nombreux romans. \\n\n","31000      She put on her hat.            \\t Elle a mis son chapeau. \\n\n","39490     You should dump Tom.        \\t Tu devrais rompre avec Tom. \\n\n","41649    I have a good salary.               \\t J'ai un bon salaire. \\n\n","34992     I can't swim at all.      \\t Je ne sais pas du tout nager. \\n\n","786                  Tom left.                     \\t Tom est parti. \\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# English character set\n","eng_vocab = set()   # use set instead of list for uniqueness\n","for sent in df.English:\n","  for char in sent:\n","    eng_vocab.add(char)\n","\n","# French character set\n","fra_vocab = set()\n","for sent in df.French:\n","  for char in sent:\n","    fra_vocab.add(char)"],"metadata":{"id":"QNxXIIY61jQh","executionInfo":{"status":"ok","timestamp":1642064741387,"user_tz":-480,"elapsed":23,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["ENG_vocab_size = len(eng_vocab) + 1\n","FRA_vocab_size = len(fra_vocab) + 1\n","\n","print('No. of English char: ', ENG_vocab_size)\n","print('No. of French char: ', FRA_vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFeOmNPQ3aHt","executionInfo":{"status":"ok","timestamp":1642064741387,"user_tz":-480,"elapsed":23,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"03c0c4f2-f1af-4e46-bc8b-ec76755eb7c4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["No. of English char:  80\n","No. of French char:  105\n"]}]},{"cell_type":"code","source":["# Assign index to each characters\n","# The characters need to be sorted\n","\n","ENG_vocab = sorted(list(eng_vocab))\n","FRA_vocab = sorted(list(fra_vocab))\n","print(ENG_vocab[30:40])\n","print(FRA_vocab[30:40])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Num1ZLa3sra","executionInfo":{"status":"ok","timestamp":1642064741388,"user_tz":-480,"elapsed":21,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"a3c0e959-37db-4cfc-d1c4-fe739880ad43"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q']\n","['E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N']\n"]}]},{"cell_type":"code","source":["# make dictionary of {char : index}\n","ENG_idx_dict = dict([(char, i + 1) for i, char in enumerate(ENG_vocab)])\n","FRA_idx_dict = dict([(char, i + 1) for i, char in enumerate(FRA_vocab)])\n","\n","print(ENG_idx_dict)\n","print(FRA_idx_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMiibAer3-Cc","executionInfo":{"status":"ok","timestamp":1642064741388,"user_tz":-480,"elapsed":20,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"bc5ac11d-84c8-4baf-f964-27c62696adee"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '°': 76, 'é': 77, '’': 78, '€': 79}\n","{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"]}]},{"cell_type":"code","source":["# Encoder (\"English\" -> Encoder input)\n","# Change every sentence in to a sequence of indexes\n","# Make a list of list --> [ [...], [...], [...] ]\n","\n","# Encoder input\n","\n","ENCODER_input = []\n","for sent in df.English:   # sentence level\n","  encoded_sent = []\n","  for english_char in sent:       # character level\n","    encoded_sent.append(ENG_idx_dict[english_char])\n","  \n","  ENCODER_input.append(encoded_sent)\n","\n","for i in ENCODER_input[:10]:\n","  print('Encoded English sentence: ', i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bm0TGheT4vqO","executionInfo":{"status":"ok","timestamp":1642064741388,"user_tz":-480,"elapsed":19,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"979e9d6c-9727-4664-a8d9-efceb7d4820b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded English sentence:  [30, 64, 10]\n","Encoded English sentence:  [30, 64, 10]\n","Encoded English sentence:  [30, 64, 10]\n","Encoded English sentence:  [31, 58, 10]\n","Encoded English sentence:  [31, 58, 10]\n","Encoded English sentence:  [41, 70, 63, 2]\n","Encoded English sentence:  [41, 70, 63, 2]\n","Encoded English sentence:  [41, 70, 63, 2]\n","Encoded English sentence:  [41, 70, 63, 2]\n","Encoded English sentence:  [41, 70, 63, 2]\n"]}]},{"cell_type":"code","source":["# Decoder input\n","\n","DECODER_input = []\n","for sent in df.French:\n","  encoded_sent = []\n","  for french_char in sent:\n","    encoded_sent.append(FRA_idx_dict[french_char])\n","\n","  DECODER_input.append(encoded_sent)\n","\n","for i in DECODER_input[:5]:\n","  print('Encoded French sentence: ', i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obPJIgsi9Ke5","executionInfo":{"status":"ok","timestamp":1642064741629,"user_tz":-480,"elapsed":258,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"0820d15c-82df-4238-c899-191918dc7fd5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded French sentence:  [1, 3, 48, 53, 3, 4, 3, 2]\n","Encoded French sentence:  [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2]\n","Encoded French sentence:  [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2]\n","Encoded French sentence:  [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2]\n","Encoded French sentence:  [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]\n"]}]},{"cell_type":"code","source":["# We can actually remove the \"<sos>\" token \n","# according to the decoder target structure\n","\n","# Decoder Target\n","\n","DECODER_TARGET = []\n","for sent in df.French:\n","  encoded_sent = []\n","  for french_char in sent:\n","    encoded_sent.append(FRA_idx_dict[french_char])\n","  \n","  encoded_sent = encoded_sent[1:]   # remove <sos> token\n","  DECODER_TARGET.append(encoded_sent)\n","\n","for i in DECODER_TARGET[:5]:\n","  print('Target French sentence: ', i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qf0U6AOZ564k","executionInfo":{"status":"ok","timestamp":1642064742517,"user_tz":-480,"elapsed":889,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"db7b07cf-fa7c-46c6-dd8a-342433afa12c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Target French sentence:  [3, 48, 53, 3, 4, 3, 2]\n","Target French sentence:  [3, 39, 53, 70, 55, 60, 57, 14, 3, 2]\n","Target French sentence:  [3, 28, 67, 73, 59, 57, 3, 4, 3, 2]\n","Target French sentence:  [3, 45, 53, 64, 73, 72, 3, 4, 3, 2]\n","Target French sentence:  [3, 45, 53, 64, 73, 72, 14, 3, 2]\n"]}]},{"cell_type":"code","source":["max_ENG_len = max([len(sent) for sent in df.English])\n","max_FRA_len = max([len(sent) for sent in df.French])\n","\n","print(\"MAX English sentence length: \", max_ENG_len)\n","print(\"MAX French sentence length: \", max_FRA_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAarKQxX7XhO","executionInfo":{"status":"ok","timestamp":1642064742518,"user_tz":-480,"elapsed":8,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"e9afd2c4-45d2-4923-8b7b-5363b232f3fc"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["MAX English sentence length:  23\n","MAX French sentence length:  76\n"]}]},{"cell_type":"code","source":["# Process padding to match the sentence lengths\n","ENCODER_input = pad_sequences(ENCODER_input, maxlen=max_ENG_len, padding='post')\n","DECODER_input = pad_sequences(DECODER_input, maxlen=max_FRA_len, padding='post')\n","DECODER_target = pad_sequences(DECODER_TARGET, maxlen=max_FRA_len, padding='post')\n"],"metadata":{"id":"UUnTFu6m7Xfe","executionInfo":{"status":"ok","timestamp":1642064743614,"user_tz":-480,"elapsed":1100,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","# Process one-hot-encoding\n","ENCODER_input = to_categorical(ENCODER_input)\n","DECODER_input = to_categorical(DECODER_input)\n","DECODER_target = to_categorical(DECODER_target)\n"],"metadata":{"id":"cE5r3rf57XdQ","executionInfo":{"status":"ok","timestamp":1642064746949,"user_tz":-480,"elapsed":3337,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["ENCODER_input[0][0:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0FJQhop7W-5","executionInfo":{"status":"ok","timestamp":1642064746950,"user_tz":-480,"elapsed":10,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"14b0a757-fa45-41f9-a8c5-3b21a2eda157"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","      dtype=float32)"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["### TRAINING Seq2Seq Model"],"metadata":{"id":"bK9PGoNi_uZH"}},{"cell_type":"markdown","source":["#### Encoder LSTM"],"metadata":{"id":"Wt5nsyGLCdMM"}},{"cell_type":"code","source":["# LSTM(units, return_state, return_sequences)\n","# \"units\": dimensionality of output space\n","# \"return_state\": whether to return the last state in addition to the output\n","# \"return_sequences\": whether to return the LAST OUTPUT\n","#                     (in the output sequence or full sequence)\n","\n","# state_h: hidden state (SHORT TERM memory)\n","# state_c: cell state (LONG TERM memory)\n","\n","\n","ENCODER_inputs = Input(shape=(None, ENG_vocab_size))\n","ENCODER_lstm = LSTM(units=256, return_state=True)\n","\n","ENCODER_outputs, state_h, state_c = ENCODER_lstm(ENCODER_inputs)\n","\n","ENCODER_states = [state_h, state_c]\n","\n","ENCODER_outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26E5VD6S-_Be","executionInfo":{"status":"ok","timestamp":1642064750385,"user_tz":-480,"elapsed":3440,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"9699fee2-beeb-47f0-ff3e-0f5ca6510ccc"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["#### Decoder LSTM"],"metadata":{"id":"CMbNVMUICfBO"}},{"cell_type":"code","source":["DECODER_inputs = Input(shape=(None, FRA_vocab_size))\n","DECODER_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n","\n","DECODER_outputs, _, _ = DECODER_lstm(DECODER_inputs, initial_state=ENCODER_states)\n","\n","DECODER_softmax_layer = Dense(FRA_vocab_size, activation='softmax')\n","DECODER_outputs = DECODER_softmax_layer(DECODER_outputs)\n"],"metadata":{"id":"lkEdNp2q--_k","executionInfo":{"status":"ok","timestamp":1642064750386,"user_tz":-480,"elapsed":3,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["INPUTS = [ENCODER_inputs, DECODER_inputs]\n","OUTPUTS = DECODER_outputs\n","\n","model = Model(INPUTS, OUTPUTS)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPAfUnT-FsDZ","executionInfo":{"status":"ok","timestamp":1642064750824,"user_tz":-480,"elapsed":10,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"d9250435-6fb0-4ac1-dc13-f41e2ff856d9"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None, 80)]   0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None, 105)]  0           []                               \n","                                                                                                  \n"," lstm (LSTM)                    [(None, 256),        345088      ['input_1[0][0]']                \n","                                 (None, 256),                                                     \n","                                 (None, 256)]                                                     \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, None, 256),  370688      ['input_2[0][0]',                \n","                                 (None, 256),                     'lstm[0][1]',                   \n","                                 (None, 256)]                     'lstm[0][2]']                   \n","                                                                                                  \n"," dense (Dense)                  (None, None, 105)    26985       ['lstm_1[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 742,761\n","Trainable params: 742,761\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["INPUTS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7FU4xogOTtB","executionInfo":{"status":"ok","timestamp":1642064750824,"user_tz":-480,"elapsed":9,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"b14b8d8d-254f-4956-b4b1-eb01d366d5e9"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<KerasTensor: shape=(None, None, 80) dtype=float32 (created by layer 'input_1')>,\n"," <KerasTensor: shape=(None, None, 105) dtype=float32 (created by layer 'input_2')>]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["print(ENCODER_input.shape)\n","print(DECODER_input.shape)\n","print(DECODER_target.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebJi8ZJbFa3D","executionInfo":{"status":"ok","timestamp":1642064750824,"user_tz":-480,"elapsed":6,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"79e35112-f36a-472e-c79f-2b2f9d74ce1d"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 23, 80)\n","(60000, 76, 105)\n","(60000, 76, 105)\n"]}]},{"cell_type":"code","source":["print(ENCODER_inputs)\n","print(DECODER_inputs)\n","print(DECODER_outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhQq2ae3Qse3","executionInfo":{"status":"ok","timestamp":1642064750825,"user_tz":-480,"elapsed":6,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"5a6e9611-640e-4e18-83c0-be65764be330"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, None, 80), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, None, 105), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n","KerasTensor(type_spec=TensorSpec(shape=(None, None, 105), dtype=tf.float32, name=None), name='dense/Softmax:0', description=\"created by layer 'dense'\")\n"]}]},{"cell_type":"code","source":["x = [ENCODER_input, DECODER_input]\n","\n","model.fit(x=x, \n","          y=DECODER_target, \n","          batch_size=64,\n","          epochs=40,\n","          validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oryAiUleGMJx","executionInfo":{"status":"ok","timestamp":1642066035011,"user_tz":-480,"elapsed":1284191,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"08b1b8dd-9a22-4d4c-bc48-6e4929a37c7e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","750/750 [==============================] - 40s 45ms/step - loss: 0.7544 - val_loss: 0.6590\n","Epoch 2/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.4559 - val_loss: 0.5340\n","Epoch 3/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.3815 - val_loss: 0.4708\n","Epoch 4/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.3390 - val_loss: 0.4318\n","Epoch 5/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.3111 - val_loss: 0.4101\n","Epoch 6/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.2899 - val_loss: 0.3931\n","Epoch 7/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.2733 - val_loss: 0.3807\n","Epoch 8/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.2604 - val_loss: 0.3714\n","Epoch 9/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.2493 - val_loss: 0.3654\n","Epoch 10/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.2397 - val_loss: 0.3599\n","Epoch 11/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.2314 - val_loss: 0.3555\n","Epoch 12/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.2239 - val_loss: 0.3533\n","Epoch 13/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.2173 - val_loss: 0.3496\n","Epoch 14/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.2112 - val_loss: 0.3494\n","Epoch 15/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.2055 - val_loss: 0.3483\n","Epoch 16/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.2004 - val_loss: 0.3474\n","Epoch 17/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1956 - val_loss: 0.3476\n","Epoch 18/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1910 - val_loss: 0.3485\n","Epoch 19/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.1869 - val_loss: 0.3508\n","Epoch 20/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.1828 - val_loss: 0.3514\n","Epoch 21/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1790 - val_loss: 0.3529\n","Epoch 22/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.1755 - val_loss: 0.3559\n","Epoch 23/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.1722 - val_loss: 0.3565\n","Epoch 24/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1691 - val_loss: 0.3566\n","Epoch 25/40\n","750/750 [==============================] - 31s 42ms/step - loss: 0.1659 - val_loss: 0.3620\n","Epoch 26/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1630 - val_loss: 0.3637\n","Epoch 27/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.1603 - val_loss: 0.3648\n","Epoch 28/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1576 - val_loss: 0.3694\n","Epoch 29/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1552 - val_loss: 0.3705\n","Epoch 30/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1528 - val_loss: 0.3730\n","Epoch 31/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1505 - val_loss: 0.3759\n","Epoch 32/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1482 - val_loss: 0.3781\n","Epoch 33/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1460 - val_loss: 0.3795\n","Epoch 34/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1440 - val_loss: 0.3832\n","Epoch 35/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1421 - val_loss: 0.3870\n","Epoch 36/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1402 - val_loss: 0.3904\n","Epoch 37/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1381 - val_loss: 0.3899\n","Epoch 38/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1365 - val_loss: 0.3936\n","Epoch 39/40\n","750/750 [==============================] - 32s 43ms/step - loss: 0.1348 - val_loss: 0.3965\n","Epoch 40/40\n","750/750 [==============================] - 32s 42ms/step - loss: 0.1331 - val_loss: 0.3997\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2bfc40c0d0>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["### TESTING the trained Seq2Seq Model\n","* The structure of the Seq2Seq model is different when it is TRAINED and when it is TESTED. \n","* When the English sentence enters the ENCODER, it returns the \"hidden state\" and the \"cell state\"\n","* Send the \"\\t\", which corresponds to 'SOS' token is sent to the DECODER\n","* The translation is processed until the sentence meets \"\\n\", which corresponds to 'EOS' token"],"metadata":{"id":"xSeyjSv7PU_Y"}},{"cell_type":"code","source":["encoder_model = Model(inputs=ENCODER_inputs, outputs=ENCODER_states)\n","encoder_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNjArbUGEwna","executionInfo":{"status":"ok","timestamp":1642066035012,"user_tz":-480,"elapsed":13,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"5be6a35d-b2d5-40df-a060-dc287006e390"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None, 80)]        0         \n","                                                                 \n"," lstm (LSTM)                 [(None, 256),             345088    \n","                              (None, 256),                       \n","                              (None, 256)]                       \n","                                                                 \n","=================================================================\n","Total params: 345,088\n","Trainable params: 345,088\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Tensor that will store the previous states\n","DECODER_state_input_h = Input(shape=(256,))\n","DECODER_state_input_c = Input(shape=(256,))\n","DECODER_states_inputs = [DECODER_state_input_h, DECODER_state_input_c]\n","\n","DECODER_outputs, state_h, state_c = DECODER_lstm(DECODER_inputs, \n","                                                 initial_state=DECODER_states_inputs)\n","\n","# Store the hidden state and the cell state\n","# which we did not use in the training process\n","DECODER_states_outputs = [state_h, state_c]\n","DECODER_outputs = DECODER_softmax_layer(DECODER_outputs)\n","\n","# Input: We use both the Decoder inputs list & Decoder state at INPUT\n","# Output: Decoder output list & Decoder state at OUTPUT\n","INPUTS = [DECODER_inputs] + DECODER_states_inputs\n","OUTPUTS = [DECODER_outputs] + DECODER_states_outputs\n","\n","DECODER_model = Model(inputs=INPUTS,\n","                      outputs=OUTPUTS)\n","\n","DECODER_model.summary()"],"metadata":{"id":"WSXJY5GdPNnc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642066035474,"user_tz":-480,"elapsed":468,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"97726bd8-d61e-4d73-fced-681c3d4d324c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, None, 105)]  0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," lstm_1 (LSTM)                  [(None, None, 256),  370688      ['input_2[0][0]',                \n","                                 (None, 256),                     'input_3[0][0]',                \n","                                 (None, 256)]                     'input_4[0][0]']                \n","                                                                                                  \n"," dense (Dense)                  (None, None, 105)    26985       ['lstm_1[1][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 397,673\n","Trainable params: 397,673\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Previous dictionary: {token : idx}\n","# Modified dictionary: {idx : token}\n","\n","idx_ENG_dict = dict((y, x) for x,y in ENG_idx_dict.items())\n","idx_FRA_dict = dict((y, x) for x,y in FRA_idx_dict.items())\n","\n","print(idx_ENG_dict)\n","print(idx_FRA_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTgdPxrPVE1S","executionInfo":{"status":"ok","timestamp":1642066035475,"user_tz":-480,"elapsed":18,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"b38ac305-2d36-43a1-9d30-8a97b5a08fdd"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["{1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: '?', 24: 'A', 25: 'B', 26: 'C', 27: 'D', 28: 'E', 29: 'F', 30: 'G', 31: 'H', 32: 'I', 33: 'J', 34: 'K', 35: 'L', 36: 'M', 37: 'N', 38: 'O', 39: 'P', 40: 'Q', 41: 'R', 42: 'S', 43: 'T', 44: 'U', 45: 'V', 46: 'W', 47: 'X', 48: 'Y', 49: 'Z', 50: 'a', 51: 'b', 52: 'c', 53: 'd', 54: 'e', 55: 'f', 56: 'g', 57: 'h', 58: 'i', 59: 'j', 60: 'k', 61: 'l', 62: 'm', 63: 'n', 64: 'o', 65: 'p', 66: 'q', 67: 'r', 68: 's', 69: 't', 70: 'u', 71: 'v', 72: 'w', 73: 'x', 74: 'y', 75: 'z', 76: '°', 77: 'é', 78: '’', 79: '€'}\n","{1: '\\t', 2: '\\n', 3: ' ', 4: '!', 5: '\"', 6: '$', 7: '%', 8: '&', 9: \"'\", 10: '(', 11: ')', 12: ',', 13: '-', 14: '.', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: '?', 27: 'A', 28: 'B', 29: 'C', 30: 'D', 31: 'E', 32: 'F', 33: 'G', 34: 'H', 35: 'I', 36: 'J', 37: 'K', 38: 'L', 39: 'M', 40: 'N', 41: 'O', 42: 'P', 43: 'Q', 44: 'R', 45: 'S', 46: 'T', 47: 'U', 48: 'V', 49: 'W', 50: 'X', 51: 'Y', 52: 'Z', 53: 'a', 54: 'b', 55: 'c', 56: 'd', 57: 'e', 58: 'f', 59: 'g', 60: 'h', 61: 'i', 62: 'j', 63: 'k', 64: 'l', 65: 'm', 66: 'n', 67: 'o', 68: 'p', 69: 'q', 70: 'r', 71: 's', 72: 't', 73: 'u', 74: 'v', 75: 'w', 76: 'x', 77: 'y', 78: 'z', 79: '\\xa0', 80: '«', 81: '»', 82: 'À', 83: 'Ç', 84: 'É', 85: 'Ê', 86: 'Ô', 87: 'à', 88: 'â', 89: 'ç', 90: 'è', 91: 'é', 92: 'ê', 93: 'ë', 94: 'î', 95: 'ï', 96: 'ô', 97: 'ù', 98: 'û', 99: 'œ', 100: '\\u2009', 101: '\\u200b', 102: '‘', 103: '’', 104: '\\u202f'}\n"]}]},{"cell_type":"code","source":["def decoding_func(INPUT_seq):\n","  # Receive state from the input of the ENCODER\n","  states_value = encoder_model.predict(INPUT_seq)\n","\n","  # Create One-Hot Vector for <SOS> ('\\t')\n","  target_sequence = np.zeros((1, 1, FRA_vocab_size))\n","  SOS_idx = FRA_idx_dict['\\t']\n","  target_sequence[0, 0, SOS_idx] = 1\n","\n","  stop_condition = False\n","  decoded_sentence = \"\"\n","\n","  # Repeat the loop until it meets the stop_condition as True\n","  while not stop_condition:\n","    # Use the state value of the previous timestep\n","    # as the initial state of the current timestep\n","    output_tokens, h, c = DECODER_model.predict([target_sequence] + states_value)\n","\n","    # Convert predicted sequence as CHARACTERS\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_char = idx_FRA_dict[sampled_token_index]\n","\n","    # Add the predicted character to the decoded sentence\n","    decoded_sentence += sampled_char\n","\n","    # Stop the loop if\n","    #   1. Meets <EOS> (\"\\n\")\n","    #   2. Went over the length of current sentence\n","    if (sampled_char == '\\n' or len(decoded_sentence) > max_FRA_len):\n","      stop_condition = True\n","    \n","    # Use current predicted character as INPUT of the next timestep\n","    target_sequence = np.zeros((1, 1, FRA_vocab_size))\n","    target_sequence[0, 0, sampled_token_index] = 1\n","\n","    # Store the current state_value to use for the next timestep\n","    states_value = [h, c]\n","  \n","  return decoded_sentence\n","\n"],"metadata":{"id":"GsqxSSn_Wpb_","executionInfo":{"status":"ok","timestamp":1642066035476,"user_tz":-480,"elapsed":16,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["for index in [3, 50, 100, 300, 1001]:\n","  input_sequence = ENCODER_input[index : index + 1]\n","  decoded_sent = decoding_func(input_sequence)\n","\n","  print(20*\"-\")\n","\n","  input_sentence = df.English[index]\n","  answer = df.French[index][2:len(df.French[index]) - 1]\n","  predicted_sentence = decoded_sent[1:len(decoded_sent) - 1]\n","\n","  print(\"Input sentence: \", input_sentence)\n","  print(\"Answer sentence: \", answer)\n","  print(\"Predicted sentence: \", predicted_sentence) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVRfedhTXl8x","executionInfo":{"status":"ok","timestamp":1642066041715,"user_tz":-480,"elapsed":6255,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"25a1fe07-d0f7-4516-a7cf-5c26ed51e996"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------\n","Input sentence:  Hi.\n","Answer sentence:  Salut ! \n","Predicted sentence:  Salut. \n","--------------------\n","Input sentence:  I see.\n","Answer sentence:  Aha. \n","Predicted sentence:  Je le vois. \n","--------------------\n","Input sentence:  Hug me.\n","Answer sentence:  Serrez-moi dans vos bras ! \n","Predicted sentence:  Serrez-moi dans vos partir ! \n","--------------------\n","Input sentence:  Help me.\n","Answer sentence:  Aidez-moi. \n","Predicted sentence:  Aide-moi. \n","--------------------\n","Input sentence:  I am sure.\n","Answer sentence:  Je suis sûr. \n","Predicted sentence:  Je suis terrible. \n"]}]},{"cell_type":"code","source":["for index in [10, 20, 30, 40, 50]:\n","  input_sequence = ENCODER_input[index : index + 1]\n","  decoded_sent = decoding_func(input_sequence)\n","\n","  print(20*\"-\")\n","\n","  input_sentence = df.English[index]\n","  answer = df.French[index][2:len(df.French[index]) - 1]\n","  predicted_sentence = decoded_sent[1:len(decoded_sent) - 1]\n","\n","  print(\"Input sentence: \", input_sentence)\n","  print(\"Answer sentence: \", answer)\n","  print(\"Predicted sentence: \", predicted_sentence) "],"metadata":{"id":"pUQ7xTUdaaW5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642066061872,"user_tz":-480,"elapsed":4119,"user":{"displayName":"j roh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXgwveP5HUF3z5d2Dybx1Fa9cIgyFNQmVK9ArPXQ=s64","userId":"03265692281681691782"}},"outputId":"f0a35d7d-9a3f-4def-e5a5-acbdb849700e"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------\n","Input sentence:  Run!\n","Answer sentence:  Cours ! \n","Predicted sentence:  File ! \n","--------------------\n","Input sentence:  Run.\n","Answer sentence:  Fuyons ! \n","Predicted sentence:  Cours ! \n","--------------------\n","Input sentence:  Jump!\n","Answer sentence:  Saute. \n","Predicted sentence:  Saute ! \n","--------------------\n","Input sentence:  Wait.\n","Answer sentence:  Attends. \n","Predicted sentence:  Attends ! \n","--------------------\n","Input sentence:  I see.\n","Answer sentence:  Aha. \n","Predicted sentence:  Je le vois. \n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"leldjNKlw5hy"},"execution_count":null,"outputs":[]}]}